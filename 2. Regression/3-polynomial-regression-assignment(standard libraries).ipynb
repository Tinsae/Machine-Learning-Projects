{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare different regression models in order to assess which model fits best. We will be using polynomial regression as a means to examine this topic.\n",
    "\n",
    "* Write a function to take a pandas Series and a degree and return a pandas DataFrame where each column is the Series to a polynomial value up to the total degree e.g. degree = 3 then column 1 is the Series column 2 is the Series squared and column 3 is the Series cubed\n",
    "* Use matplotlib to visualize polynomial regressions\n",
    "* Use matplotlib to visualize the same polynomial degree on different subsets of the data\n",
    "* Use a validation set to select a polynomial degree\n",
    "* Assess the final fit using test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using lambda to create polynomial features\n",
    "tmp = pd.Series([1., 2., 3.])\n",
    "tmp_cubed = tmp.apply(lambda x: x**3)\n",
    "print(tmp)\n",
    "print(tmp_cubed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new columns\n",
    "ex_df = pd.DataFrame()\n",
    "ex_df['power_1'] = tmp\n",
    "print(ex_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_dataframe(feature, degree):\n",
    "    # assume that degree >= 1\n",
    "    # initialize the SFrame:\n",
    "    poly_df = pd.DataFrame()\n",
    "    # and set poly_sframe['power_1'] equal to the passed feature\n",
    "    poly_df['power_1'] = feature\n",
    "    # first check if degree > 1\n",
    "    if degree > 1:\n",
    "        # then loop over the remaining degrees:\n",
    "        # range usually starts at 0 and stops at the endpoint - 1. We want it to start at 2 and stop at degree\n",
    "        for power in range(2, degree + 1): \n",
    "            # first we'll give the column a name:\n",
    "            name = 'power_' + str(power)\n",
    "            # then assign poly_sframe[name] to the appropriate power of feature\n",
    "            poly_df[name] = feature ** power\n",
    "    return poly_df\n",
    "# test it\n",
    "print(polynomial_dataframe(tmp, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "sales = pd.read_csv(\"../../ML Data & Script/kc_house_data.csv\")\n",
    "sales.head()\n",
    "\n",
    "# sort by sqft_living and price (for plotting purposes)\n",
    "sales = sales.sort_values(by=['sqft_living', 'price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use statsmodels\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "# use sklearn\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# degree one polynomial\n",
    "X = polynomial_dataframe(sales['sqft_living'], 1)\n",
    "Y = sales['price'] # add price to the data since it's the target\n",
    "model_one_sk = LinearRegression()\n",
    "model_one_sk.fit(X, Y)\n",
    "print(str(model_one_sk.intercept_) + str(model_one_sk.coef_))\n",
    "\n",
    "print(model_one_sk.score(X, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# degree one polynomial\n",
    "X = polynomial_dataframe(sales['sqft_living'], 1)\n",
    "Y = sales['price']\n",
    "X = sm.add_constant(X)\n",
    "model_one = smf.OLS(Y, X).fit()\n",
    "model_one.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's take a look at the weights before we plot\n",
    "print('Parameters: ', model_one.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X['power_1'], Y,'.',\n",
    "        X['power_1'], model_one.predict(X),'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# degree two polynomial\n",
    "X = polynomial_dataframe(sales['sqft_living'], 2)\n",
    "Y = sales['price']\n",
    "X = sm.add_constant(X)\n",
    "model_two = smf.OLS(Y, X).fit()\n",
    "model_two.summary()\n",
    "plt.plot(X['power_1'], Y,'.',\n",
    "        X['power_1'], model_two.predict(X),'-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# degree three polynomial\n",
    "X = polynomial_dataframe(sales['sqft_living'], 3)\n",
    "Y = sales['price']\n",
    "X = sm.add_constant(X)\n",
    "model_three = smf.OLS(Y, X).fit()\n",
    "model_three.summary()\n",
    "plt.plot(X['power_1'], Y,'.',\n",
    "        X['power_1'], model_three.predict(X),'-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# degree 15 polynomial\n",
    "X = polynomial_dataframe(sales['sqft_living'], 15)\n",
    "Y = sales['price']\n",
    "X = sm.add_constant(X)\n",
    "model_fifteenth = smf.OLS(Y, X).fit()\n",
    "model_fifteenth.summary()\n",
    "plt.plot(X['power_1'], Y,'.',\n",
    "        X['power_1'], model_fifteenth.predict(X),'-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing Data and Re-learning\n",
    "\n",
    "* Split the sales data into four subsets of roughly equal size.\n",
    "* Estimate a 15th degree polynomial model on all four subsets of the data. \n",
    "* Print the coefficients (you should use .print_rows(num_rows = 16) to view all of them) and plot the resulting fit (as we did above).\n",
    "\n",
    "4 subsets (`set_1`, `set_2`, `set_3`, `set_4`) of approximately equal size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-read the data to remove the sorting\n",
    "sales = pd.read_csv(\"../../ML Data & Script/kc_house_data.csv\")\n",
    "sales = sales[['sqft_living', 'price']]\n",
    "# randomize data\n",
    "sales = sales.sample(frac=1,random_state=5)\n",
    "amount = sales.shape[0] // 4\n",
    "# create the four sets\n",
    "set_1 = sales[0:amount * 1].sort_values(by=['sqft_living', 'price'])\n",
    "set_2 = sales[amount * 1:amount * 2].sort_values(by=['sqft_living', 'price'])\n",
    "set_3 = sales[amount * 2:amount * 3].sort_values(by=['sqft_living', 'price'])\n",
    "set_4 = sales[amount * 3:].sort_values(by=['sqft_living', 'price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,6))\n",
    "fig.subplots_adjust(hspace = 0.4, wspace = 0.2)\n",
    "fig.suptitle(\"Model Variance\")\n",
    "fig.add_subplot(221)\n",
    "\n",
    "# degree 15 polynomial for set1\n",
    "X = polynomial_dataframe(set_1['sqft_living'], 15)\n",
    "Y = set_1['price']\n",
    "X = sm.add_constant(X)\n",
    "model_set1 = smf.OLS(Y, X).fit()\n",
    "plt.plot(X['power_1'], Y,'.',\n",
    "        X['power_1'], model_set1.predict(X),'-')\n",
    "\n",
    "# degree 15 polynomial for set2\n",
    "X = polynomial_dataframe(set_2['sqft_living'], 15)\n",
    "Y = set_2['price']\n",
    "X = sm.add_constant(X)\n",
    "model_set2 = smf.OLS(Y, X).fit()\n",
    "fig.add_subplot(222)\n",
    "plt.plot(X['power_1'], Y,'.',\n",
    "        X['power_1'], model_set2.predict(X),'-')\n",
    "\n",
    "# degree 15 polynomial for set1\n",
    "X = polynomial_dataframe(set_3['sqft_living'], 15)\n",
    "Y = set_3['price']\n",
    "X = sm.add_constant(X)\n",
    "model_set3 = smf.OLS(Y, X).fit()\n",
    "fig.add_subplot(223)\n",
    "plt.plot(X['power_1'], Y,'.',\n",
    "        X['power_1'], model_set3.predict(X),'-')\n",
    "\n",
    "# degree 15 polynomial for set4\n",
    "X = polynomial_dataframe(set_4['sqft_living'], 15)\n",
    "Y = set_4['price']\n",
    "X = sm.add_constant(X)\n",
    "model_set4 = smf.OLS(Y, X).fit()\n",
    "fig.add_subplot(224)\n",
    "plt.plot(X['power_1'], Y,'.',\n",
    "        X['power_1'], model_set4.predict(X),'-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_set1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_set2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_set3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_set4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting a Polynomial Degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever we have a \"magic\" parameter like the degree of the polynomial there is one well-known way to select these parameters: validation set. (We will explore another approach in week 4).\n",
    "\n",
    "We split the sales dataset 3-way into training set, test set, and validation set as follows:\n",
    "\n",
    "* Split our sales data into 2 sets: `training_and_validation` and `testing`. Use `random_split(0.9, seed=1)`.\n",
    "* Further split our training data into two sets: `training` and `validation`. Use `random_split(0.5, seed=1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = sales['sqft_living']\n",
    "y = sales['price']\n",
    "# obtain 10% test data and remaining 90%\n",
    "X_remaining, X_test, y_remaining, y_test = train_test_split(X, y, test_size=0.1, random_state=5)\n",
    "# obtain 45% train and 45% validation data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_remaining, y_remaining, test_size=0.5, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For degree in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15] (to get this in python type range(1, 15+1))\n",
    "    * Build a dataframe of polynomial data of train_data['sqft_living'] at the current degree\n",
    "    * Add train_data['price'] to the polynomial SFrame\n",
    "    * Learn a polynomial regression model to sqft vs price with that degree on TRAIN data\n",
    "    * Compute the RSS on VALIDATION data \n",
    "        * (here you will want to use .predict()) for that degree and you will need to make a polynmial dataframe using validation data.\n",
    "* Report which degree had the lowest RSS on validation data (remember python indexes from 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_residual_sum_of_squares(model, data, outcome):\n",
    "    # First get the predictions\n",
    "    predictions=model.predict(data)    \n",
    "    # Then compute the residuals/errors\n",
    "    RSS = outcome - predictions\n",
    "    # Then square and add them up\n",
    "    RSS =(RSS * RSS).sum()\n",
    "    return(RSS)    \n",
    "rss_list = []\n",
    "for i in range(1, 15+1):\n",
    "    # poly dataframe using training data\n",
    "    X_train_poly = polynomial_dataframe(X_train, i)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_poly, y_train)    \n",
    "    \n",
    "    # making polynomial dataframe using validation data\n",
    "    X_val_poly = polynomial_dataframe(X_val, i)\n",
    "      \n",
    "    rss = get_residual_sum_of_squares(model, X_val_poly, y_val)\n",
    "   \n",
    "    # calcualte rss using sklearn\n",
    "    #from sklearn import metrics\n",
    "    #rss2 = poly_df.shape[0] * metrics.mean_squared_error(model.predict(poly_df), y_val)\n",
    "    \n",
    "    rss_list.append(rss)\n",
    "    print(\"{} {:E}\" .format(i ,rss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the smallest RSS on validation set\n",
    "min_index = np.argmin(rss_list) + 1\n",
    "min_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting complexity vs validation error\n",
    "plt.plot(list(np.arange(1,16,1)), rss_list)\n",
    "plt.xlabel(\"Complexity\")\n",
    "plt.ylabel(\"Validation Error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "X_train_poly = polynomial_dataframe(X_train, min_index)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_poly, y_train)    \n",
    "rss_train = get_residual_sum_of_squares(model, X_train_poly, y_train)\n",
    "#rss_train = X_train_poly.shape[0] * metrics.mean_squared_error(model.predict(X_train_poly), y_train)\n",
    "\n",
    "\n",
    "X_test_poly = polynomial_dataframe(X_test, min_index)\n",
    "\n",
    "rss_test = get_residual_sum_of_squares(model, X_test_poly, y_test)\n",
    "\n",
    "print(\"Training Error: {:E}\" .format(rss_train))\n",
    "print(\"Test Error: {:E}\" .format(rss_test))\n",
    "#print(\"Validation Error: {:E}\".format(rss_list[min_index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reflection\n",
    "\n",
    "Polynomial regression is a model which has polynomial degrees of the input variable. Some people call them feature transformations.\n",
    "In this notebook, sqft_living is the predictor variable and price is the dependent variable. \n",
    "The polynomial features are sqft_living, sqft_living_squared, sqft_living_cubed, sqft_living_raised_to_four,.... \n",
    "I wrote a function that creates polynomial features up to a given degree. \n",
    "The house price data is split into 2 parts: 90% Train_Validation_Set, 10% Test_Set\n",
    "90% Train_Val_set is further split into two equal parts: 50% Training Set, 50% Validation Set.\n",
    "\n",
    "* Training Set: 45%\n",
    "* Validation Set: 45%\n",
    "* Test Set: 10%\n",
    "    \n",
    "The model is trained on training data. It is good to use the Validation Set, to select hyper-parameters like degree of a polynomial. The smallest validation error is found to be a 2 degree polynomial model = sqft + sqft^2 + intercept\n",
    "\n",
    "The 2 degree polynomial model is tested on the test-set. The test-error is an approximation of generalization error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_poly.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_poly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_poly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
