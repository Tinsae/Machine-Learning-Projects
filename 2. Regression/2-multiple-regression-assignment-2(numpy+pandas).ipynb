{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view     ...      grade  sqft_above  \\\n",
       "0      5650     1.0           0     0     ...          7        1180   \n",
       "1      7242     2.0           0     0     ...          7        2170   \n",
       "2     10000     1.0           0     0     ...          6         770   \n",
       "3      5000     1.0           0     0     ...          7        1050   \n",
       "4      8080     1.0           0     0     ...          8        1680   \n",
       "\n",
       "   sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0              0      1955             0    98178  47.5112 -122.257   \n",
       "1            400      1951          1991    98125  47.7210 -122.319   \n",
       "2              0      1933             0    98028  47.7379 -122.233   \n",
       "3            910      1965             0    98136  47.5208 -122.393   \n",
       "4              0      1987             0    98074  47.6168 -122.045   \n",
       "\n",
       "   sqft_living15  sqft_lot15  \n",
       "0           1340        5650  \n",
       "1           1690        7639  \n",
       "2           2720        8062  \n",
       "3           1360        5000  \n",
       "4           1800        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "sales = pd.read_csv(\"../../ML Data & Script/kc_house_data.csv\")\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_data(data, features, output):\n",
    "    # add a column with all ones to a dataframe\n",
    "    data['constant'] = 1 \n",
    "    # add the column 'constant' to the front of the features list so that we can extract it along with the others:\n",
    "    # this is how you combine two lists\n",
    "    features = ['constant'] + features \n",
    "    # get a dataframe with the selected features and convert to numpy matrix\n",
    "    X = data[features].values\n",
    "    # get output column(pandas series)\n",
    "    output = data[output]\n",
    "    # convert pandas series to numpy array\n",
    "    y = output.values\n",
    "    return(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1180\n",
      "221900.0\n"
     ]
    }
   ],
   "source": [
    "# Checking the data at the first row for sqft\n",
    "print(sales['sqft_living'][0])\n",
    "#Checking the output of the first row\n",
    "print(sales['price'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first row, features [[   1 1180]]\n",
      "first row, output [[221900.]]\n",
      "[[   1 1180]]\n"
     ]
    }
   ],
   "source": [
    "# the [] around 'sqft_living' makes it a list\n",
    "(X, y) = get_numpy_data(sales, ['sqft_living'], 'price')\n",
    "# this accesses the first row of the data the ':' indicates 'all columns'\n",
    "print(\"first row, features\",  X[0, :].reshape(1,2))\n",
    "# and the corresponding output\n",
    "print(\"first row, output\", y[0].reshape(1,1)) \n",
    "print(X[0,:].reshape(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21613, 2)\n",
      "(21613, 1)\n"
     ]
    }
   ],
   "source": [
    "# shape of X and y\n",
    "print(X.shape)\n",
    "y = y.reshape(-1,1)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1181.0\n"
     ]
    }
   ],
   "source": [
    "# predict output given weights\n",
    "# the example weights\n",
    "my_weights = np.array([1., 1.]) \n",
    "# we'll use the first data point\n",
    "first_data_point = X[0,]\n",
    "# 1 * 1 + 1 * 1180\n",
    "y_pred = np.dot(first_data_point, my_weights)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate prediction for the whole data\n",
    "def predict_output(data_matrix, weights):\n",
    "    # assume feature_matrix is a numpy matrix containing the features as columns and weights is a corresponding numpy array\n",
    "    # create the predictions vector by using np.dot()\n",
    "    pred = np.dot(data_matrix, weights)\n",
    "    return(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1181.0\n",
      "2571.0\n"
     ]
    }
   ],
   "source": [
    "# test prediction\n",
    "# (21613, 2).(2,1)\n",
    "test_pred = predict_output(X, my_weights)\n",
    "# should be 1181.0\n",
    "print(test_pred[0])\n",
    "# should be 2571.0\n",
    "print(test_pred[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute derivative\n",
    "def feature_derivative(errors, feature):\n",
    "    # Assume that errors and feature are both numpy arrays of the same length (number of data points)\n",
    "    # compute twice the dot product of these vectors as 'derivative' and return the value\n",
    "    derivative=2* (np.dot(errors,feature))\n",
    "    return(derivative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-23345850016.0\n",
      "-23345850016.0\n"
     ]
    }
   ],
   "source": [
    "# test feature derivative\n",
    "(X, y) = get_numpy_data(sales, ['sqft_living'], 'price') \n",
    "my_weights = np.array([0., 0.]) # this makes all the predictions 0\n",
    "yhat = predict_output(X, my_weights) \n",
    "# just like SFrames 2 numpy arrays can be elementwise subtracted with '-': \n",
    "# prediction errors in this case is just the -example_output\n",
    "errors = yhat - y \n",
    "# let's compute the derivative with respect to 'constant', the \":\" indicates \"all rows\"\n",
    "feature = X[:,0] \n",
    "derivative = feature_derivative(errors, feature)\n",
    "print(derivative)\n",
    "# should be the same as derivative\n",
    "print(-np.sum(y) * 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "def regression_gradient_descent(X, y, initial_weights, step_size, tolerance):\n",
    "    converged = False \n",
    "    # make sure it's a numpy array\n",
    "    weights = np.array(initial_weights) \n",
    "    while not converged:\n",
    "        # compute the predictions based on feature_matrix and weights using your predict_output() function\n",
    "        yhat = predict_output(X, weights)\n",
    "        # compute the errors as predictions - output\n",
    "        errors = yhat - y\n",
    "        # initialize the gradient sum of squares\n",
    "        gradient_sum_squares = 0 \n",
    "        # while we haven't reached the tolerance yet, update each feature's weight\n",
    "        # loop over each weight\n",
    "        for i in range(len(weights)): \n",
    "            # Recall that feature_matrix[:, i] is the feature column associated with weights[i]\n",
    "            # compute the derivative for weight[i]:\n",
    "            derivative = feature_derivative(errors, X[:, i])\n",
    "            # add the squared value of the derivative to the gradient sum of squares (for assessing convergence)\n",
    "            gradient_sum_squares += derivative * derivative\n",
    "            # subtract the step size times the derivative from the current weight\n",
    "            weights[i] -= step_size * derivative\n",
    "        # compute the square-root of the gradient sum of squares to get the gradient magnitude:\n",
    "        gradient_magnitude = sqrt(gradient_sum_squares)\n",
    "        if gradient_magnitude < tolerance:\n",
    "            converged = True\n",
    "    return(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-46999.88720259    283.46383063]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# run gradient descent, simple linear regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(sales, sales['price'], test_size=0.2, random_state=0)\n",
    "# let's test out the gradient descent\n",
    "(X, y) = get_numpy_data(X_train, ['sqft_living'], 'price')\n",
    "initial_weights = np.array([-47000., 1.])\n",
    "step_size = 7e-12\n",
    "tolerance = 2.5e7\n",
    "simple_weights = regression_gradient_descent(X, y, initial_weights, step_size, tolerance)\n",
    "print(simple_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very close to the weights obtained using sklearn\n",
    "* Intercept: -48257.063591028564\n",
    "* Slope: 283.96855715512993"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# test data, simple features\n",
    "(X_test, y_test) = get_numpy_data(X_test, ['sqft_living'], 'price')\n",
    "y_hat_model_one = predict_output(X_test, simple_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "358353.39059137006"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicited house price for the first house\n",
    "y_hat_model_one[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9.99999757e+04  2.47055837e+02  6.47974873e+01]\n"
     ]
    }
   ],
   "source": [
    "# running multiple regression\n",
    "# sqft_living15 is the average squarefeet for the nearest 15 neighbors.\n",
    "X_train, X_test, y_train, y_test = train_test_split(sales, sales['price'], test_size=0.2, random_state=0)\n",
    "adv_features = ['sqft_living', 'sqft_living15']  \n",
    "(X_train, y_train) = get_numpy_data(X_train, adv_features, 'price')\n",
    "initial_weights = np.array([-100000., 1., 1.])\n",
    "step_size = 4e-12\n",
    "tolerance = 1e9\n",
    "adv_weights = regression_gradient_descent(X_train, y_train, initial_weights, step_size, tolerance)\n",
    "print(adv_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# test on a test set\n",
    "(X_test, y_test) = get_numpy_data(X_test, adv_features, 'price')\n",
    "y_hat_model_two = predict_output(X_test, adv_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345950.2780906761"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model2 prediction for the first house\n",
    "y_hat_model_two[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297000.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-61353.39059137006\n",
      "-48950.27809067612\n"
     ]
    }
   ],
   "source": [
    "# difference with model one\n",
    "print(y_test[0] - y_hat_model_one[0])\n",
    "# difference with model two\n",
    "print(y_test[0] - y_hat_model_two[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267729995270518.6\n",
      "262684098596668.75\n"
     ]
    }
   ],
   "source": [
    "# RSS\n",
    "# model_one RSS\n",
    "print(((y_hat_model_one - y_test) ** 2).sum())\n",
    "# model_two RSS\n",
    "print(((y_hat_model_two - y_test) ** 2).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_one performed better for the first house on the testset, but overall model_two has lower RSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F-test\n",
    "* unexplained model variance:\n",
    "\n",
    "$$SSE_F=\\sum(y_i-\\hat{y}_i)^2$$\n",
    "\n",
    "* unexplained variance in reduced model:\n",
    "\n",
    "$$SSE_R=Var_y = \\sum(y_i-\\bar{y})^2$$\n",
    "\n",
    " * number of parameters in the model:\n",
    "\n",
    "$$p_F = 2 (\\alpha \\text{ and } \\beta)$$\n",
    "\n",
    " * number of parameters in the reduced model:\n",
    "\n",
    "$$p_R = 1 (\\alpha)$$\n",
    "\n",
    " * number of datapoints:\n",
    "\n",
    "$$n$$\n",
    "\n",
    " * degrees of freedom of $SSE_F$:\n",
    "\n",
    "$$df_F = n - p_F$$\n",
    "\n",
    " * degrees of freedom of $SSE_R$:\n",
    "\n",
    "$$df_R = n - p_R$$\n",
    "\n",
    "These pieces come together to give us the full equation for the F-test:\n",
    "\n",
    "$$F=\\dfrac{SSE_F-SSE_R}{df_F-df_R}Ã·\\dfrac{SSE_F}{df_F}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read these: \n",
    "\n",
    "http://facweb.cs.depaul.edu/sjost/csc423/documents/f-test-reg.htm\n",
    "\n",
    "http://eric.univ-lyon2.fr/~ricco/tanagra/fichiers/en_Tanagra_Calcul_P_Value.pdf\n",
    "\n",
    "https://www.youtube.com/watch?v=JBXkKOPZDsc&ab_channel=mathtutordvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree of freedom 1:  4322\n",
      "degree of freedom 2:  4321\n",
      "fstatistic:  3976.417886342636\n",
      "1.1102230246251565e-16 False\n"
     ]
    }
   ],
   "source": [
    "# calcuate FValue from scratch\n",
    "((y_hat_model_one - y_test) ** 2).sum()\n",
    "\n",
    "SSEf = ((y_hat_model_one - y_test) ** 2).sum()\n",
    "SSEr = ((y_test.mean() - y_test) ** 2).sum()\n",
    "n = y_test.shape[0]\n",
    "pF = 2\n",
    "pR = 1\n",
    "dfF = n - pF\n",
    "dfR = n - pR\n",
    "print(\"degree of freedom 1: \", dfR)\n",
    "print(\"degree of freedom 2: \", dfF)\n",
    "\n",
    "F = ((SSEf - SSEr) / (dfF - dfR)) * (dfF / SSEf)\n",
    "print(\"fstatistic: \", F)\n",
    "# the null hypothesis: all of the regression parameters are zero\n",
    "import scipy\n",
    "#Or whatever you want your alpha to be.\n",
    "alpha = 0.05 \n",
    "pvalue = 1 - scipy.stats.f.cdf(F, dfR, dfF)\n",
    "print(pvalue, pvalue > alpha)\n",
    "# Reject the null hypothesis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree of freedom 1:  4322\n",
      "degree of freedom 2:  4320\n",
      "fstatistic:  2067.422888779355\n",
      "1.1102230246251565e-16 False\n"
     ]
    }
   ],
   "source": [
    "# calcuate FValue from scratch\n",
    "((y_hat_model_one - y_test) ** 2).sum()\n",
    "\n",
    "SSEf = ((y_hat_model_two - y_test) ** 2).sum()\n",
    "SSEr = ((y_test.mean() - y_test) ** 2).sum()\n",
    "n = y_test.shape[0]\n",
    "pF = 3\n",
    "pR = 1\n",
    "dfF = n - pF\n",
    "dfR = n - pR\n",
    "print(\"degree of freedom 1: \", dfR)\n",
    "print(\"degree of freedom 2: \", dfF)\n",
    "\n",
    "F = ((SSEf - SSEr) / (dfF - dfR)) * (dfF / SSEf)\n",
    "print(\"fstatistic: \", F)\n",
    "# the null hypothesis: all of the regression parameters are zero\n",
    "import scipy\n",
    "#Or whatever you want your alpha to be.\n",
    "alpha = 0.05 \n",
    "pvalue = 1 - scipy.stats.f.cdf(F, dfR, dfF)\n",
    "print(pvalue, pvalue > alpha)\n",
    "# Reject the null hypothesis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look the cumulative area up to the statistic is almost one, so remaining area is very close to 0\n",
    "scipy.stats.f.cdf(F, dfR, dfF )\n",
    "# 1 - cdf gives the remaining area.\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method rv_continuous.cdf of <scipy.stats._continuous_distns.f_gen object at 0x000002424C64A9E8>>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
