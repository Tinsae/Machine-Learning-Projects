{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "sales = pd.read_csv(\"../../ML Data & Script/kc_house_data.csv\")\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_data(data, features, output):\n",
    "    # add a column with all ones to a dataframe\n",
    "    data['constant'] = 1 \n",
    "    # add the column 'constant' to the front of the features list so that we can extract it along with the others:\n",
    "    # this is how you combine two lists\n",
    "    features = ['constant'] + features \n",
    "    # get a dataframe with the selected features and convert to numpy matrix\n",
    "    X = data[features].values\n",
    "    # get output column(pandas series)\n",
    "    output = data[output]\n",
    "    # convert pandas series to numpy array\n",
    "    y = output.values\n",
    "    return(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the data at the first row for sqft\n",
    "print(sales['sqft_living'][0])\n",
    "#Checking the output of the first row\n",
    "print(sales['price'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the [] around 'sqft_living' makes it a list\n",
    "(X, y) = get_numpy_data(sales, ['sqft_living'], 'price')\n",
    "# this accesses the first row of the data the ':' indicates 'all columns'\n",
    "print(\"first row, features\",  X[0, :].reshape(1,2))\n",
    "# and the corresponding output\n",
    "print(\"first row, output\", y[0].reshape(1,1)) \n",
    "print(X[0,:].reshape(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of X and y\n",
    "print(X.shape)\n",
    "y = y.reshape(-1,1)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict output given weights\n",
    "# the example weights\n",
    "my_weights = np.array([1., 1.]) \n",
    "# we'll use the first data point\n",
    "first_data_point = X[0,]\n",
    "# 1 * 1 + 1 * 1180\n",
    "y_pred = np.dot(first_data_point, my_weights)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate prediction for the whole data\n",
    "def predict_output(data_matrix, weights):\n",
    "    # assume feature_matrix is a numpy matrix containing the features as columns and weights is a corresponding numpy array\n",
    "    # create the predictions vector by using np.dot()\n",
    "    pred = np.dot(data_matrix, weights)\n",
    "    return(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test prediction\n",
    "# (21613, 2).(2,1)\n",
    "test_pred = predict_output(X, my_weights)\n",
    "# should be 1181.0\n",
    "print(test_pred[0])\n",
    "# should be 2571.0\n",
    "print(test_pred[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute derivative\n",
    "def feature_derivative(errors, feature):\n",
    "    # Assume that errors and feature are both numpy arrays of the same length (number of data points)\n",
    "    # compute twice the dot product of these vectors as 'derivative' and return the value\n",
    "    derivative=2* (np.dot(errors,feature))\n",
    "    return(derivative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test feature derivative\n",
    "(X, y) = get_numpy_data(sales, ['sqft_living'], 'price') \n",
    "my_weights = np.array([0., 0.]) # this makes all the predictions 0\n",
    "yhat = predict_output(X, my_weights) \n",
    "# just like SFrames 2 numpy arrays can be elementwise subtracted with '-': \n",
    "# prediction errors in this case is just the -example_output\n",
    "errors = yhat - y \n",
    "# let's compute the derivative with respect to 'constant', the \":\" indicates \"all rows\"\n",
    "feature = X[:,0] \n",
    "derivative = feature_derivative(errors, feature)\n",
    "print(derivative)\n",
    "# should be the same as derivative\n",
    "print(-np.sum(y) * 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "def regression_gradient_descent(X, y, initial_weights, step_size, tolerance):\n",
    "    converged = False \n",
    "    # make sure it's a numpy array\n",
    "    weights = np.array(initial_weights) \n",
    "    while not converged:\n",
    "        # compute the predictions based on feature_matrix and weights using your predict_output() function\n",
    "        yhat = predict_output(X, weights)\n",
    "        # compute the errors as predictions - output\n",
    "        errors = yhat - y\n",
    "        # initialize the gradient sum of squares\n",
    "        gradient_sum_squares = 0 \n",
    "        # while we haven't reached the tolerance yet, update each feature's weight\n",
    "        # loop over each weight\n",
    "        for i in range(len(weights)): \n",
    "            # Recall that feature_matrix[:, i] is the feature column associated with weights[i]\n",
    "            # compute the derivative for weight[i]:\n",
    "            derivative = feature_derivative(errors, X[:, i])\n",
    "            # add the squared value of the derivative to the gradient sum of squares (for assessing convergence)\n",
    "            gradient_sum_squares += derivative * derivative\n",
    "            # subtract the step size times the derivative from the current weight\n",
    "            weights[i] -= step_size * derivative\n",
    "        # compute the square-root of the gradient sum of squares to get the gradient magnitude:\n",
    "        gradient_magnitude = sqrt(gradient_sum_squares)\n",
    "        if gradient_magnitude < tolerance:\n",
    "            converged = True\n",
    "    return(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run gradient descent, simple linear regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(sales, sales['price'], test_size=0.2, random_state=0)\n",
    "# let's test out the gradient descent\n",
    "(X, y) = get_numpy_data(X_train, ['sqft_living'], 'price')\n",
    "initial_weights = np.array([-47000., 1.])\n",
    "step_size = 7e-12\n",
    "tolerance = 2.5e7\n",
    "simple_weights = regression_gradient_descent(X, y, initial_weights, step_size, tolerance)\n",
    "print(simple_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very close to the weights obtained using sklearn\n",
    "* Intercept: -48257.063591028564\n",
    "* Slope: 283.96855715512993"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data, simple features\n",
    "(X_test, y_test) = get_numpy_data(X_test, ['sqft_living'], 'price')\n",
    "y_hat_model_one = predict_output(X_test, simple_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicited house price for the first house\n",
    "y_hat_model_one[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running multiple regression\n",
    "# sqft_living15 is the average squarefeet for the nearest 15 neighbors.\n",
    "X_train, X_test, y_train, y_test = train_test_split(sales, sales['price'], test_size=0.2, random_state=0)\n",
    "adv_features = ['sqft_living', 'sqft_living15']  \n",
    "(X_train, y_train) = get_numpy_data(X_train, adv_features, 'price')\n",
    "initial_weights = np.array([-100000., 1., 1.])\n",
    "step_size = 4e-12\n",
    "tolerance = 1e9\n",
    "adv_weights = regression_gradient_descent(X_train, y_train, initial_weights, step_size, tolerance)\n",
    "print(adv_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on a test set\n",
    "(X_test, y_test) = get_numpy_data(X_test, adv_features, 'price')\n",
    "y_hat_model_two = predict_output(X_test, adv_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2 prediction for the first house\n",
    "y_hat_model_two[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference with model one\n",
    "print(y_test[0] - y_hat_model_one[0])\n",
    "# difference with model two\n",
    "print(y_test[0] - y_hat_model_two[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RSS\n",
    "# model_one RSS\n",
    "print(((y_hat_model_one - y_test) ** 2).sum())\n",
    "# model_two RSS\n",
    "print(((y_hat_model_two - y_test) ** 2).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_one performed better for the first house on the testset, but overall model_two has lower RSS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
